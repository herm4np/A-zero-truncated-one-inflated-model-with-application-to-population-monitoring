---
title: "A zero-truncated one-inflated model with application to population monitoring"
author: "Herman Persson"
date: "`r format(Sys.time(), '%B %Y')`"
bibliography: references.bib
output:
  pdf_document:
    fig_caption: yes
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=FALSE,warning=FALSE,message=FALSE,error=FALSE)
```

```{r, include=FALSE}
library(tidyverse)
library(starsExtra)
library(ggpubr)
source("code.R")
```

# Abstract

When one-inflation in data arises due to samples from individuals being misidentified as samples from non-existent with probability $p$, a large bias arises in the population estimate if the inflation is not taken into account. This inflation causes a greater bias compared to previously analysed inflation where it arises due to individuals with some probability $p_B$ succeed in deviating from being observed more than once (@bohning2019identity, @godwin2017one). By using distributions that take into account that data contains one-inflation of the type miss identification, we can reduce the bias. With the same parameters in a base distribution and $p = p_B$, inflation that arises due to incorrect identification is always expected to give greater bias and variance on the population estimate than the corresponding behavior caused inflation population estimate. When we apply our models to brown bear data from the department of Environmental Research and Monitoring at the Swedish Museum of Natural History we see no evidence of one-inflation and note that further analysis regarding individual heterogeneity of the bears is required for a reliable population estimate.

# Introduction

To draw conclusions about a populations size is an important problem in animal monitoring as well as other areas where the amount of information about the target group's behavior is limited. A common method is capture-recapture where a part the population is observed as well as identified and one with the help of the observed individuals attempt to estimate the total underlying population size. The problem can be summarized as wanting to estimate the size of the total population $N$, which is the sum of the number of observed individuals $n$ and the number of unobserved individuals $n_0$. Since $n$ is known from data, the problem is reduced to finding $n_0$. A common approach to yield inference about $n_0$ is to use the available data to estimate the parameters of the zero-truncated distribution which corresponds to the distribution of number of samples per individual. Using this approach there are several different methods for dealing with problems such as individual heterogeneity and contamination, e.g. @chao1987estimating and @zelterman1988robust, but as shown in @godwin2017estimation, they fall very biased in the presence of one-inflation. One-inflation in data means that, as e.g. post-collection error or due to a behavioral change in the population, extra ones occur compared to the underlying distribution. The special case of one-inflation have been discussed in previous mathematical reports, methods and models for dealing with the problem have been developed. In @godwin2017estimation inflation occur as a consequence of behavioral change, some individuals change their behavior after being observed once and succeed in avoidance from further observations. In the report we see how one, with the probability of this behavioral change $p_B$, can adjust an underlying poisson distribution to include these extra ones. A more general variant of the method is developed in @bohning2019identity where the one-inflated distribution 
for an arbitrary base probability density function (PDF) $f$ and corresponding zero-truncated PDF $f_+$ is shown to follow

\begin{align}\begin{cases}(1-p_B)+p_Bf_+(x,\theta)\hspace{5mm}& \textrm{for } x = 1, \ \\ p_Bf_+(x,\theta)\hspace{5mm}& \textrm{for } x > 1.\end{cases}\end{align}

In this report we will look at the previously untreated one-inflation which occur when a sample from an individual with some probability $p$ is incorrectly identified as a non-existent individual (ghost). Ghost inflation in data could occur due to genotyping errors or if photo identification is used. The case of ghost inflation differs from behavior inflation in a number of ways. One difference which is that the extra ones generated by ghost inflation does not represent real individuals, but in in behavior inflation they do. A second main difference is that the base distribution is affected by the inflation as the ghosts in data occurs at the expense of observations of real individuals with the same probability for all individuals, in contrast to behavior inflation where individuals who does not change their behavior is unaffected by the inflation. A third main difference is that the extra number of ones generated by individual $i$ in ghost inflation is $p \cdot E[X_i]$, where $X_i$ is the number of observations of said individual, where as in behavior inflation one individual only can contribute with one extra one. Because of the differences between ghost and behavioral inflation, the problems are obviously not equivalent, but as we will see later in this report, they are closely related.

The purpose of developing the models in this report is to apply them to data regarding the brown bear population in Sweden. Regions of Sweden which are inhabited by brown bears are divided into four parts which all have been monitored by the department of Environmental Research and Monitoring at the Swedish Museum of Natural History (NRM) since 2015. The bear population is surveyed in each region with five year intervals (one region each year and one year without survey). During the survey hunters in the region are asked to collect scat-samples. These samples are sent to the NRM, where samples are genotyped and stored in a database of observed individuals.

# Method

We will assume that the population is closed during an ongoing inventory, i.e. that no individuals die, are born, move in or out. In this case the sample result will follow the vector $y = (y_1, y_2, ..., y_N)$, where $y_i$ denotes the number of samples from individual $i$ and $N$ is the population size. If each sample comes from a randomly selected individual, independent of the other individuals, $y$ will follow a multinomial distribution with probabilities $(1/N, ..., 1/N)$. Since the multinomial distribution is not desirable to work with, we transform the distribution for number of samples from one individual to a poisson distribution (@baker1994multinomial). We then get that $y_i\sim Po (\lambda=m/N)$ where $m$ is the total number of samples collected. Note that all individuals from which we collect zero samples ($y_i=0$) will be unobserved.

Due to the differences between the behavioral and ghost inflation we can not directly use (1) as the PDF in the case of ghosts, though we use the slightly different parametrisation

$$f_{+1} = \begin{cases}(1-\omega)+\omega f_+(x,\theta, p)\hspace{5mm}& \textrm{for } x = 1, \ \\ \omega f_+(x,\theta, p)\hspace{5mm}& \textrm{for } x > 1.\end{cases}$$

In this distribution $\omega$, which is dependent on both $p$ and our base distribution $f$, adjusts the extra weight at one and the zero-truncated distribution has been adjusted to take into account the expected decreased number of samples from real individuals. The distribution will be proven to be useful in this report as we can derive $\omega = 1/(1+pE[X_i]/(1-f(0)))$ (see proof in Appendix (1)) and $f_+(x,\theta, p)$ often is easily derived. However, $f_{+1}$ is not the only useful model for population estimation. As we shall see later in this report, by disregarding the number of ones and using a zero-one-truncated distribution we will be able avoid some bias which occur when estimating the population using $f_{+1}$ for low values of $p$, at the cost of increased variance. Therefore, we will also develop models which use a zero-one-truncated distribution $f_{++}$ to analyse one-inflated data.

## Population estimation

To estimate the population in a capture-recapture setting a variant of the Horvitzâ€“Thompson estimator (@horvitz1952generalization) where $\hat{N}_{HT} = n/(1-f(0,\hat{\theta}))$ is commonly used as the estimator is asymptotically unbiased under the condition that $\hat{\theta}$ is unbiased. In @bohning2019identity it is noted that in the case of one-inflation in data $\hat{N}_{HT}$ can be modified such as 

$$\hat{N} = \frac{n-f_1}{1-f(0,\hat{\theta})-f(1,\hat{\theta})}.$$

Here $f_1$ denotes the total number of ones in data and the estimator is unbiased under the same condition as $\hat{N}_{HT}$. In @bohning2019identity the estimator is further developed to count the extra ones, but in our case this is not desired as the extra ones does not represent real individuals. The estimator $\hat{N}$ is thus useful for both our zero-truncated one-inflated and zero-one-truncated models in the case of ghost inflation and will be used to estimate the population for these models in this report.

## The poisson model

Let us begin by denoting the PDF of the regular poisson distribution as $p(x, \lambda)$. Under the assumptions in the beginning of the method chapter the number of samples per individual of the observed individuals will be zero-truncated poisson distributed with PDF

\begin{align}p_+(x, \lambda) = \frac{p(x, \lambda)}{1- p(0,\lambda)} = \frac{\lambda^x e^{-\lambda}}{(1-e^{-\lambda})x!} = \frac{\lambda^x}{(e^\lambda- 1)x!}.\end{align}

Now lets assume that ghost inflation occur and a sample from one individual for some reason can be incorrectly identified as a sample from a not previously observed and non existent individual with some probability $p \in (0,1)$. For all $p$ larger than zero this will result in an increased number of observed ones, so called one-inflation, as well as a decreased number of expected observations per individual. To incorporate these conditions into our distribution we consider the new PDF of the zero-truncated one-inflated poisson (ZTOIP) model. The distribution for ZTOIP, denoted as $p_{+1}$, is then

$$p_{+1}(x,\lambda, p) = \begin{cases} (1 - \omega) + \omega p_+(x,\theta) \hspace{5mm}& \textrm{for } x = 1,\\ 
\omega p_+(x,\theta) & \textrm{for } x > 1. \end{cases}$$

In the ZTOIP distribution $\omega = 1/(1+p\lambda/(1-p(0, \theta)))$ (see proof in Appendix (1)) adjusts the extra mass at $1$ and $\theta = \lambda(1-p)$ is the adjusted density parameter with consideration to the reduced number of expected observation per individual. 

If we are not necessarily interested in the exact values of $p$ and $\lambda$, another useful way to view data would be to ignore all the individuals observed only once and use a zero-one-truncated poisson model (ZOTP). As we shall see later, by using this model we will increase the uncertainty of our estimates but avoid some bias for small $p$ values which occur when using the ZTOIP model as deflation is not allowed. In case of the ZTOP model we have the PDF

$$p_{++}(x, \theta) = \frac{p(x, \theta)}{1- p(0,\theta) - p(1,\theta)} = \frac{\theta^x}{(e^{\theta} - \theta - 1)x!}.$$

The final poisson based distribution we will use is the zero-truncated poisson (ZTP). By using this distribution we will be able to see the effect on population estimates when existing inflation is not taken into account and how well our other models compare when there is no inflation. The ZTP PDF can be seen in (2).

## The negative binomial model

All individuals being observed with the same probability is rarely the case and it is important that our model can take into account individual capture probability before applying it to bear data. Under zero heterogeneity, the problem of population estimation in capture recapture is much simpler as there is less variance in data. By expanding our poisson model to a negative binomial model we can introduce individual capture probability for individual $i$ by letting the parameter of its poisson distribution be distributed according to a Gamma distribution. More precisely

$$\theta_i = \lambda_i (1 - p) \sim \Gamma (k\lambda, \frac{k}{1-p}).$$

This means that $E[\theta_i] = \lambda(1-p)$, $Var[\theta_i] = \lambda(1-p)^2/k$ and we are able to adjust for over dispersion by adjusting $k$. Note that the distribution collapses to Po$(\lambda(1-p))$ as $k\to \infty$. We know from e.g. @wiki:Negative_binomial_distribution that

$$X_i \sim \Gamma (r, \frac{p}{1-p}) \hspace{5mm} \Rightarrow \hspace{5mm} \textrm{Po}(X_i) \stackrel{d}{=} \textrm{NBin}(r, p),$$

and with some short calculations we then get 

\begin{align}\theta_i \sim \Gamma(k\lambda, \frac{k}{1-p}) \hspace{5mm} \Rightarrow \hspace{5mm} \textrm{Po}(\theta_i) \stackrel{d}{=} \textrm{NBin}(k\lambda,\frac{k}{1-p+k}).\end{align}

Note that we can allow all $k > 0$ by using the extended negative binomial distribution which extends the binomial coefficient to all real-values using the gamma function. Let us denote the PDF of our base distribution $\textrm{Po}(\theta_i)$ in (3) as $g(x,\lambda,k,p)$. Similarly to the poisson models we want to construct three different models for estimating the total population; zero-truncated one-inflated negative binomial (ZTOINB), zero-one-truncated negative binomial (ZOTNB) and the zero-truncated negative binomial (ZTNB). In the case of the ZTNB distribution we get the PDF

$$g_+(x,\lambda, k,p) = \frac{\frac{\Gamma(x+k\lambda)}{x!\Gamma(k\lambda)}\Big(1- \frac{k}{1+k-p}\Big)^x}{\Big(\frac{k}{1+k-p}\Big)^{-k\lambda} - 1}.$$

Note that when we use the ZTNB model to estimate the population we will assume that $p =0$. In the ZOTNB model we get 

$$g_{++}(x,\lambda, k, p)=\frac{\frac{\Gamma(x+k\lambda)}{x!\Gamma(k\lambda)}\Big(1- \frac{k}{1-p+k}\Big)^x}{\Big(\frac{k}{1+k-p}\Big)^{-k\lambda}-1-k\lambda\Big(1-\frac{k}{1+k-p}\Big)}.$$

In the case of the ZTOINB distribution we similarly to the ZTOIP model use our corresponding zero truncated distribution with the addition of $\omega$ to adjust the extra mass at 1. Hence, we have the ZTOINB PDF

$$g_{+1}(x,\lambda, k, p)=\begin{cases}(1-\omega)+\omega g_+(x,\lambda, k,p) \hspace{5mm}& \textrm{for } x = 1,\\ 
\omega g_+(x,\lambda, k,p)  &\textrm{for } x >1. \end{cases}$$

In this case, similarly to the poisson model, $\omega = 1/(1+p\lambda/(1-g(0,\lambda,k,p)))$ (proof in Appendix (1)).

## Bear data

The distribution for the number of samples per individual each year can be seen in Figure 1. Note that the survey of 2015 and 2020 was done in the same region. In Figure 1 we see that most bears were observed only a few number of times and that the most common number of observations is one, for all five years. It is conceivable that some of these ones occur due to genotyping errors when identifying the bears which would lead to ghost inflation. An existing one-inflation in data will cause an overestimation of the population in data as it will increase the estimation of $n_0$. As we expect heterogeneity in the brown bear population we will investigate the suspected inflation by applying our negative binomial models to data.

```{r fig.cap="Histogram of number of samples per bear"}
data_captures %>%
  group_by(year, id) %>%
  summarize(n_obs = n()) %>%
  ggplot(aes(x = n_obs)) + 
    geom_histogram(binwidth = 1) + 
    facet_grid(~year) +
    labs(x = "Number of observations", y = "Count") +
    theme_bw()
```

## Simulations

All parameter estimates are calculated via the maximum likelihood method. Since the likelihood functions of some of our models are unable to be maximized algebraically all likelihoods will be maximized numerically for the sake of comparability. An important note is the fact that the Negative Binomial model is rather unstable when using numerical maximization and therefore some non-existent trends might be visible for even very large simulations. A link to all the code used in the creation of this report can be found in the Appendix.

# Results 

Since we want to see how well our different models estimate the population, a natural starting point is to use simulation study. We will start by looking at the consequences of not taking ghost inflation into account to then move on to our models that include inflation.

## Simulations 

To begin our analysis we simulate data from the ZTOIP distribution and estimate the population with the regular ZTP model using $\hat{N}_{HT}$, which does not take into account that data is inflated. Results of the simulation are shown in Figure 2. The mean percent error of the population estimate ($100\cdot\hat N/N$) for each combination of $\lambda$, $p$ and $N$ is calculated from 100 simulations. A comparison with the bias in the case of behavior inflation from @godwin2017estimation can be seen in Table 1.

```{r fig.cap="ZTP, relative bias of mean population estimate"}
PP_SIM %>%
  group_by(lambda, p, N) %>%
  summarize(avg_N_est_percent_error = mean(N_est)*100/N-100) %>%
  filter(N %in% c(500, 2500)) %>%
  ggplot(aes(x = p, y = avg_N_est_percent_error, group = as.factor(lambda))) +
    geom_line(aes(linetype=as.factor(lambda))) +
    geom_point(size = 1) +
    scale_linetype_manual(values=c("dotted", "twodash", "solid"), name = expression(paste(lambda, ":"))) +
    facet_grid(~N, labeller = label_both) +
    labs(x = "p", y = expression(paste("% bias of ",bar(N))), fill = "") +
    theme_bw()
```

```{r}
PP_SIM %>% 
  filter(!p %in% c(0, 0.2, 0.4), lambda != 3, N == 500) %>%
  group_by(p, lambda) %>%
  summarize(avg_N_est_percent_error = mean(N_est*100/N - 100) %>% round(1)) %>%
  mutate(type = "Ghosts") %>%
  full_join(tibble(lambda = c(1, 1, 2, 2), p = c(0.1, 0.3, 0.1, 0.3), avg_N_est_percent_error = c(6.2, 23.2, 3.0, 12.0), type = "Behavior")) %>%
  arrange(type, lambda, p) %>%
  knitr::kable(caption = "Percentage bias of $\\bar N _{ZTP}$ for diffrent inflation types as N = 500", col.names = c("$p/p_B$","$\\lambda$","$\\%$ bias of $\\bar N _{ZTP}$","Type"))
```

To see how well our ZTOIP and ZOTP are able to estimate the population we simulate data from the ZTOIP distribution 1000 times for each combination of three different values for $N$, $\lambda$ and $p$. For each simulation the base distribution parameters are estimated using the ZTOIP, ZOTP and ZTP models and the population size is estimated with $\hat{N}_{HT}$ for ZTP and $\hat{N}$ for ZTOIP and ZOTP. To get an understanding of how the variance and bias differ between the ZTOIP and ZOTP population estimators we observe Table 2. In the table, together with the mean percent error, we see the root-mean-square error (RMSE) as well as $90\%$ and $99\%$ confidence intervals. The bounds of our two-sided confidence intervals are chosen from our population estimates and contains $90\%$ and $99\%$, respectively, of the estimates.

```{r}
P_SIM %>%
  pivot_longer(c(N_est_ztoip, N_est_zotp, N_est_ztp), names_to = "type", values_to = "N_est") %>%
  filter(N == 500, lambda == 2)  %>%
  mutate(type = str_remove(type, "N_est_") %>% 
           toupper(),
         N_est_2 = N_est/N) %>%
  arrange(N_est) %>%
  group_by(type, p) %>%
  summarise(N_mean_est = mean(N_est) %>% round(), 
            conf_90 = paste0("[", c(N_est[50], N_est[950]) %>% toString(), "]"), 
            conf_99 = paste0("[", c(N_est[10], N_est[990]) %>% toString(), "]"), 
            sd = sqrt(mean((N_est - N)^2)) %>% round()) %>%
  knitr::kable(caption = "ZTOIP, ZOTP and ZTP, confidence intervals and RMSE of pupulation estimate as $N = 500$ and $\\lambda = 2$", 
               col.names = c("Type","$p$","$\\bar N$","90% CI","99% CI","RMSE"))
```


As we expand our model and introduce individual heterogeneity in the negative binomial distribution the effects of the population estimate as $\lambda$, $N$ and $p$ varies are unaltered (Appendix (3)). Therefore, we will focus on the consequences on our population estimates as $k$ varies. In Table 3 the mean percent error, RMSE and $90\%$ and $99\%$ confidence intervals can be seen for the ZOTNB population estimate of 1000 simulations repeated for different combinations of $\lambda$ and $k$. 

```{r}
NB_SIM %>%
  pivot_longer(c(N_est_ztoinb, N_est_zotnb, N_est_ztnb), names_to = "type", values_to = "N_est") %>%
  filter(type == "N_est_zotnb", N == 500, p == 0.1)  %>%
  full_join(NB_SIM_ext %>% mutate(type = "N_est_zotnb")) %>%
  mutate(N_est_2 = N_est/N) %>%
  arrange(N_est) %>%
  group_by(lambda, k) %>%
  summarise(N_mean_est = mean(N_est) %>% round(), conf_90 = paste0("[", c(N_est[50], N_est[950]) %>% toString(), "]"), conf_99 = paste0("[", c(N_est[10], N_est[990]) %>% toString(), "]"), sd = sqrt(mean((N - N_est)^2)) %>% round()) %>% 
  knitr::kable(caption = "ZOTNB, confidence intervals and RMSE of population estimate as $N = 500$ and $p = 0.1$", col.names = c("$\\lambda$","$k$","$\\bar N$","90% CI","99% CI","RMSE")) 
```

## Application on bear data

Before we apply our models to bear data it is important that we get an understanding of how well bear data fits a negative binomial model. We do this by creating QQ-plots where we compare the distribution of our bear data, as seen in Figure 1, with the theoretical quantiles of a ZTNB distribution with parameters estimated by the ZOTNB model. The result can be seen in Figure 3. It is important to notice that the data which consists of all years combined (All) does not meet the model assumptions to the same degree as one year separately since some bears have been observed during two different surveys and therefore have a much higher probability of being observed.

```{r fig.cap="QQ-plot, bear data and theoretical NBin quantiles"}
par(mfrow=c(2,3))
qqplot(qqplot_gen_2(data_summary),
       data_summary$n_obs,
       ylab = "All", 
       xlab = "Theoretical quantiles")
abline(0, 1, col = 'red')
qqplot(qqplot_gen_2(data_summary_2015),
       data_summary_2015$n_obs,
       ylab = "2015",
       xlab = "Theoretical quantiles")
abline(0, 1, col = 'red')
qqplot(qqplot_gen_2(data_summary_2016),
       data_summary_2016$n_obs, 
       ylab = "2016",
       xlab = "Theoretical quantiles")
abline(0, 1, col = 'red')
qqplot(qqplot_gen_2(data_summary_2017),
       data_summary_2017$n_obs,
       ylab = "2017",
       xlab = "Theoretical quantiles")
abline(0, 1, col = 'red')
qqplot(qqplot_gen_2(data_summary_2019),
       data_summary_2019$n_obs,
       ylab = "2019",
       xlab = "Theoretical quantiles")
abline(0, 1, col = 'red')
qqplot(qqplot_gen_2(data_summary_2020),
       data_summary_2020$n_obs,
       ylab = "2020",
       xlab = "Theoretical quantiles")
abline(0, 1, col = 'red')
```

In Table 4 the estimated underlying distribution parameters from the ZTOINB distribution are shown together with the estimated population size by all of our three negative binomial models.

```{r}
tibble(year = c("All", 2015, 2016, 2017, 2019, 2020), data = list(data_summary, data_summary_2015, data_summary_2016, data_summary_2017, data_summary_2019, data_summary_2020)) %>%
  rowwise() %>%
  mutate(n = length(data %>% pull(n_obs)),
         par_ZTOINB = list(data %>% pull(n_obs) %>% ztoinb_ml_fit())[[1]][1],
         par_ZOTNB = list(data %>% pull(n_obs) %>% zotnb_ml_fit())[[1]][1],
         par_ZTNB = list(data %>% pull(n_obs) %>% ztnb_ml_fit())[[1]][1],
         lambda_hat = par_ZTOINB[[1]] %>% round(3),
         k_hat = par_ZTOINB[[2]] %>% round(3),
         p_hat = par_ZTOINB[[3]] %>% round(3),
         N_ZTOINB = N_nb(par_ZTOINB, data %>% pull(n_obs)),
         N_ZOTNB = N_nb(par_ZOTNB, data %>% pull(n_obs)),
         N_ZTNB = N_ztnb(par_ZTNB, data %>% pull(n_obs))) %>%
  select(year, n, lambda_hat, k_hat, p_hat, N_ZTOINB, N_ZOTNB, N_ZTNB) %>%
  knitr::kable(caption = "Population and samples per bear distribution paramter estimates", col.names = c("Year","$n$","$\\hat \\lambda_{g_{+1}}$","$\\hat k_{g_{+1}}$","$\\hat p_{g_{+1}}$","$\\hat N _{g_{+1}}$","$\\hat N_{g_{++}}$","$\\hat N_{g_{+}}$"))
```

# Discussion

In @godwin2017estimation where the inflation parameter $p_B$ directly corresponds to the expected number of extra ones generated by one individual, the estimation of the population for the regular ZTP model is positively biased. From Table 1 where the bias of the ZTP model in our simulations is compared to the bias in @godwin2017estimation we can see that the two different types of inflation result in much different bias, more precisely the bias of our estimator when ghost inflation is present is much greater than for behavioral inflation. In the case of behavioral inflation the bias reduces as $\lambda$ increase, which is not the case for ghost inflation where the opposite is true. The difference can be explained as in behavioral inflation, when $\lambda$ increase, the expected number of extra ones generated by the inflation does not change, but $\hat{\lambda}$ will increase which makes $\hat{n}_0$ and the positive bias decrease. In the case of ghost inflation an increased $\lambda$ also means an increased number of extra ones which will lead to negative bias in $\hat\lambda$. This negative effect dominates the positive effect on the bias previously described which causes $\hat{n_0}$ to increase and the positive bias in $\hat N$ increase. As can be seen in Figure 2 the relative bias of the estimator grows exponentially as $p$ increase and the lower the value of $\lambda$ the more does an increased population size reduce the bias. In @godwin2017estimation a similar result for behavioral inflation can be observed as an increased population size reduce the relative bias more for lower values of $\lambda$ and the relative bias also grows exponentially as $p$ increase.

As both the ZTOIP and ZOTP models in our modeling for ghost inflation use akin population estimators one could suspect their result to be similar. However, as can be seen in Table 2, their population estimates differ, especially for low values of $p$. Both of the models suffer positive bias as a consequence of high uncertainty for low values of $\lambda$ and $N$ (see Appendix (2)), but for low values of $p$ the positive bias in the ZTOIP model is dominated by a negative bias. The negative bias can be explained as the ZTOIP model will estimate $p> 0$ in about half of the cases where $p = 0$ due to variance in the number of ones in data. The negative bias decrease as $N$ increases since data then converge towards theoretical distribution and the relative variance in the number of ones decrease. One possible way to remove this bias would be to expand the model to allow deflation, i.e. $\mid p\mid <1$, as this would create a symmetry in $\hat{p}$ for low values of $p$ which is currently missing (see Appendix (4)). In @godwin2017estimation deflation is allowed and as a result the ZTOIP population estimate does not suffer from negative bias. However, the method used is not directly applicable to our models and another approach is necessary in the case of ghost inflation. Due to the negative bias of the ZTOIP estimator, the ZOTP estimator is a better alternative for low values of $p$, and since we can see in Table 2 that ZTOIP and ZOTP converges towards each other for higher values of $p$, ZOTP looks to be the better estimator between the two. Its however important to mind the high bias of the ZOTP population estimator when $\lambda$ is small. If we compare our ghost inflation estimator ZOTP to the behavior inflation estimator ZTOIP in @godwin2017estimation we see that the our estimate is much more sensitive to low population sizes, low values of $\lambda$ and high inflation parameters and is always expected to giver higher bias and error. The difference is expected as the ZOTP estimator does not take into account the number of ones and ghost inflation means a greater number of ones and zeroes compared to behavioral inflation. This also implies that if one were to find an estimator in ghost inflation which allows deflation it is expected to give greater bias and error compared to the corresponding estimator in behavioral inflation.

As we expand our model to $NBin(k\lambda,k/(1-p+k))$ and introduce $k$ to adjust for over dispersion we get a heavier tail on our base distribution compared to a poisson distribution with the same $\lambda$ and $p$. As a result the variance of our population estimations increase. As can be observed from Table 3 the ZOTNB confidence intervals and RMSE is strictly greater than for the ZOTP estimator using the same $\lambda$ and $p$ in Table 2. The result is expected due to the increased variance of the negative binomial model. As can be seen in Appendix (3) and the full data of our ZTOINB simulations, for low values of $\lambda$ and high values of $k$ the ZTOINB model provide better estimates and should definitely be considered when choosing between the models of model. A better understanding of the difference between the poisson and the negative binomial distributions can be obtained by studying the difference between the two distributions shown in Appendix (5). In @godwin2017one the effect of behavioral inflation in the negative binomial model is examined and for $\lambda = 2$, $N = 500$ and $p = 0.1$ the ZTOINB population estimate when behavioral deflation is present (which allows deflation) has less bias and variance compared to our ZOTNB estimator for ghost inflation. The difference is explained analogously to that in the poisson model.

When estimating the bear population and distribution parameters for the number of observations, we can from Table 4 see that the inflation for all year except 2017 is estimated to be zero. Assuming that the negative binomial distribution provides a good fit with data this result go against the hypothesis that bear data include inflation. Based on QQ-plots in Figure 3, data seem to fit the negative binomial distribution quite well for lower values, however the distribution fits poorly on data for higher values. This in not be overlooked as the negative binomial distribution is very flexible and existing discrepancy is alarming. Therefore, to say that the data fits the distribution well would not be true. The problem of finding the correct model has proven to be very difficult in capture-recapture and from @link2003nonidentifiability we know that it is impossible to distinguish among reasonable models of heterogeneity (without additional information) even though they can yield very unlike inferences about population size. This makes the problem of finding a better fit for bear data very difficult and more information should be taken into account for reliable estimates.

It is possible that there often exists an understanding of how a possible inflation value $p$ can arise and be distributed. In the case of genotyping errors this is especially true since there in many cases is possible to get a good understanding of what the probability error can be based on the method used (@pompanon2005genotyping). If we have a prior to our study have an understanding of our inflation parameter $p$, priori distributions can be of use. In @tuoto2022bayesian the use of priori in behavior inflation is introduced and similar work would be interesting to apply to the case of ghost inflation.

A summary from our analysis and comparison with other reports is that ghost inflation compared with behavioral inflation always leads to more uncertain population estimates when the same base distribution is used. As mentioned previously an improvement of zero-truncated one-inflated estimates can be done by expanding the model to include deflation and such a model would be ideal. However, this improvement does not mean that population estimate in ghost inflation will be as good as in behavior inflation with same base distribution as the expected bias and error still will be higher using the same base distribution and $p=p_B$. 

# Appendix

All the code used in the production of this report can be found at https://github.com/herm4np/A-zero-truncated-one-inflated-model-with-application-to-population-monitoring.

## (1) Derivation of $\omega$

\begin{align*}
f_{+1}(1) & 
=\frac{pNE[X_i]+Nf(1,p)}{pNE[X_i] + N\sum_{k=1}^{\infty}f(k,p)}\\
&=\frac{pE[X_i]+f(1,p)}{pE[X_i] + \sum_{k=1}^{\infty}f(k,p)}\\
&=\frac{pE[X_i]+f(1,p)}{pE[X_i]+(1-f(0,p))}\\
&=\frac{pE[X_i]}{1-f(0,p)+pE[X_i]}+\frac{f(1,p)}{1-f(0,p)+pE[X_i]}\\
&=1-\frac{1-f(0,p)+pE[X_i]}{1-f(0,p)+pE[X_i]}+\frac{pE[X_i]}{1-f(0,p)+pE[X_i]}+\frac{\frac{f(1,p)}{1-f(0,p)}}{\frac{1-f(0,p)+pE[X_i]}{1-f(0,p)}}\\
&=1-\frac{1-f(0,p)+pE[X_i]}{1-f(0,p)}+\frac{f_{+}(1,p)}{1-\frac{pE[X_i]}{1-f(0,p)}}\\
&=\Bigg(1-\frac{1}{1-\frac{pE[X_i]}{1-f(0,p)}}\Bigg)+\frac{1}{1-\frac{pE[X_i]}{1-f(0,p)}}f_{+}(1,p)\\
&= (1-\omega) + \omega f_+(1,p)\\
\Rightarrow \omega &=\frac{1}{1-\frac{pE[X_i]}{1-f(0,p)}}.
\end{align*}

## (2) Relative bias of mean population estimate

ZTOIP (left) and ZOTP (right).

```{r}
ggarrange(P_SIM %>%
            group_by(lambda, p, N) %>%
            summarize(avg_N_est_percent_error = mean(N_est_ztoip)*100/N-100) %>%
            ggplot(aes(x = p, y = avg_N_est_percent_error, group = as.factor(lambda), color = as.factor(lambda))) +
            geom_line() +
            scale_color_manual(values=c("red", "blue", "green"), name = expression(paste(lambda, ":"))) +
            facet_grid(~N) +
            ylim(c(-6.2, 6.2)) +
            labs(x = "p", y = expression(paste("% bias of ", bar(N))), fill = "") + 
            scale_x_continuous(breaks = c(0, 0.05, 0.1),
                               labels=c("0", "0.05", "0.1")) +
            theme_bw(),
          P_SIM %>%
            group_by(lambda, p, N) %>%
            summarize(avg_N_est_percent_error = mean(N_est_zotp)*100/N-100) %>%
            ggplot(aes(x = p, y = avg_N_est_percent_error, group = as.factor(lambda), color = as.factor(lambda))) +
            geom_line() +
            scale_color_manual(values=c("red", "blue", "green"), name = expression(paste(lambda, ":"))) +
            facet_grid(~N) +
            ylim(c(-6.2, 6.2)) +
            labs(x = "p", y = "", fill = "") + 
            theme(legend.position = "top") +
            scale_x_continuous(breaks = c(0, 0.05, 0.1),
                               labels=c("0", "0.05", "0.1")) +
            theme_bw(),
          common.legend = TRUE)
```

## (3) Log-bias of NBin population estimates 

Faceted horizontally with respect to $k$. Log for improved visibility.

```{r}
NB_SIM %>% 
  pivot_longer(c(N_est_ztoinb, N_est_ztnb, N_est_zotnb), names_to = "type", values_to = "N_est") %>%
  mutate(type = str_remove(type, "N_est_") %>% toupper()) %>%
  group_by(lambda, p, k, type) %>%
  summarize(avg_N_est_percent_error = mean(log(N_est)*100/log(N)-100)) %>%
  ggplot(aes(x = p, y = avg_N_est_percent_error, group = as.factor(lambda), color = as.factor(lambda))) +
    geom_line() +
    scale_color_manual(values=c("red", "blue", "green"), name = expression(paste(lambda, ":"))) +
    facet_grid(type~k, scales ="free_y") +
    labs(x = "p", y = expression(paste("% bias of log(",bar(N), ")")), fill = "")+
    theme(legend.position = "top") +
    scale_x_continuous(breaks = c(0, 0.05, 0.1)) +
    theme_bw()
```

## (4) Histogram of $\hat{p}$

Estimated by OIPP. Faceted horizontally with respect to $N$ and vertically to $p$. $\lambda \in \{1,2,3\}$.

```{r}
P_SIM %>%
  mutate(p_hat = fit_ztoip[[1]][2]) %>%
  ggplot(aes(x = p_hat)) +
    geom_histogram(binwidth = 0.01) +
    facet_grid(p~N) +
    labs(x = expression(paste(hat(p))), y = "Count", fill = "") +
    theme_bw()
```

## (5) Comparison of base distribution NBin and Po

Poisson distribution shown in grey, extra ones excluded, $\lambda = 2$ and $p = 0.1$. Faceted horizontally with respect to $k$.

```{r}
tibble("Poisson" = qpois(ppoints(1000), lambda = 2*(1 - 0.1)),
       "k_0.2" = qnbinom(ppoints(1000), size = 2*0.2, prob = 0.2/(1 - 0.1 + 0.2)),
       "k_0.6" = qnbinom(ppoints(1000), size = 2*0.6, prob = 0.6/(1 - 0.1 + 0.6)),
       "k_1" = qnbinom(ppoints(1000), size = 2*1, prob = 1/(1 - 0.1 + 1)),
       "k_2" = qnbinom(ppoints(1000), size = 2*2, prob = 2/(1 - 0.1 + 2))) %>%
  pivot_longer(-c(Poisson), names_to = "type", values_to = "q") %>%
  ggplot() + 
    geom_histogram(mapping = aes(x = Poisson, y = ..count../1000), 
                  bins = 16, alpha = 0.7,
                  fill = "gray40", size = 0.5) + 
    geom_histogram(mapping = aes(x = q, y = ..count../1000, 
                            color = type, fill = type), 
              stat = "bin", bins = 16, size = 0.5,
              alpha = 0.7) + 
    guides(color = "none", fill = "none") + 
    labs(x = "Observations", y = "Density") + 
    xlim(c(0, 15)) +
    ylim(c(0, 0.3)) +
    facet_wrap(~ type, nrow = 1, labeller= as_labeller(c(k_0.2="0.2", k_0.6="0.6", k_1="1", k_2="2")))
```

# References
